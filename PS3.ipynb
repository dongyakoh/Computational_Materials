{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd5538c",
   "metadata": {},
   "source": [
    "## Problem Set 3\n",
    "\n",
    "Please work on Python coding exercises. You should add a new cell right below each exercise to write down your code and execute the code. **This assignment is due on Jan 19th.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e678093",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "In the class, we numerically solved a neoclassical growth model using the *policy function iteration* algorithm. However, the actual code was not following the PFI algorithm specified in the lecture slides.\n",
    "\n",
    "In this exercise, you will solve the neoclassical growth model using a (modfied version of) policy function iteration algorithm written in the lecture slides. More specifically, you write a code based on the algorithm below. **Please check if the policy function converges to a true policy function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f53d6",
   "metadata": {},
   "source": [
    "## Policy Function Iteration Algorithm\n",
    "\n",
    "An alternative way of solving the problem is a *policy function iteration* or *Howard's improvement algorithm*. As its name indicates, this algorithm starts with a guess on the policy function and keeps updating the policy function instead of value function. Sometimes, this algorithm solves the problem a little faster than the VFI. Here is a brief sketch of the algorithm.\n",
    "\n",
    "In the neoclassical growth model setting, let $h()$ be the policy function, $k' = h(k)$.\n",
    "\n",
    "1. Choose any $ h^0 \\in \\mathbb{R}^n $, and specify $ \\varepsilon > 0 $; set $ i = 0 $  \n",
    "1. From the initial guess of the policy function, for each $k$ we have $\\tilde{k}' = h^0(k)$.\n",
    "1. Given $(\\tilde{k}',k)$, we can compute $u(c) = u(f(k)+(1-\\delta) - \\tilde{k}')$.\n",
    "1. If our policy function $h^i$ for any iteration $i=0,1,2,...$ was the optimal specification $h^*$, then the max operator in the bellman equation should be eliminated:\n",
    "\\begin{equation}\n",
    "v^* = u(f(k)+(1-\\delta)k-h^*) + \\beta v^*\n",
    "\\end{equation}\n",
    "Then, from this specification, we can solve for $v^*$: \n",
    "\\begin{equation}\n",
    "v^* = \\frac{1}{1-\\beta}u(f(k)+(1-\\delta)k-h^*)\n",
    "\\end{equation}\n",
    "If $h^i$ is not optimal, then the equation above serves as an updating equation. Therefore, by the $i$-th iteration, the updated value function becomes\n",
    "\\begin{equation}\n",
    "v^{i+1} = \\frac{1}{1-\\beta}u(f(k)+(1-\\delta)k-h^{i})\n",
    "\\end{equation}\n",
    "1. Using the updated value function, obtain a new policy function for the next iteration:\n",
    "\\begin{equation}\n",
    "h^{i+1} = \\underset{k'}{\\operatorname{argmax}} u(f(k)+(1-\\delta)k-k') + \\beta v^{i+1}\n",
    "\\end{equation}\n",
    "1. If $ \\lVert h^{i+1} - h^i\\rVert <  [(1 - \\beta) / (2\\beta)] \\varepsilon $,\n",
    "  then stop; otherwise, set $ i = i + 1 $ and go to step 4  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55328609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ngm_pfi:\n",
    "    # INITIALIZATION OF NGM CLASS WITH GIVEN PREDETERMINED PARAMETERS VALUES\n",
    "    def __init__(self,  nk      = 1000,\n",
    "                        α       = 0.34,\n",
    "                        β       = 0.95,\n",
    "                        σ       = 2,\n",
    "                        δ       = 0.04):\n",
    "\n",
    "        # GRID FOR k\n",
    "        self.nk             = nk\n",
    "\n",
    "        # MODEL PARAMETERS\n",
    "        self.α              = α\n",
    "        self.β              = β\n",
    "        self.σ              = σ\n",
    "        self.δ              = δ\n",
    "        \n",
    "        # COMPUTE STEADY STATE CAPITAL-LABOR RATIO\n",
    "        self.k_ss           = ((1/β-1+δ)/α)**(1/(α-1))\n",
    "\n",
    "        # INITIALIZE GRID POINTS\n",
    "        self.kgrid          = self.init_kgrid()\n",
    "        \n",
    "        # INITIALIZE VALUE FUNCTION AND POLICY FUNCTION\n",
    "        self.kp             = self.kgrid\n",
    "        cons                = self.kgrid**self.α + (1 - self.δ)*self.kgrid - self.kp\n",
    "        self.V              = self.util(cons)/(1-self.β)\n",
    "\n",
    "\n",
    "    def init_kgrid(self):\n",
    "        '''\n",
    "        This function constructs and returns grid points for state k.\n",
    "        The grid points are in equidistance.\n",
    "        '''\n",
    "        # THE MIN AND MAX VALUES OF k RANGE\n",
    "        kmin = 0.5*self.k_ss\n",
    "        kmax = 1.5*self.k_ss\n",
    "\n",
    "        # DISCRETIZE THE RANGE WITH NK GRID POINTS BY AN EQUIDISTANCE\n",
    "        self.kgrid = np.linspace(kmin,kmax,self.nk)\n",
    "        \n",
    "        # RETURN THE GRID POINTS\n",
    "        return self.kgrid\n",
    "\n",
    "\n",
    "    def util(self,cons):\n",
    "        '''\n",
    "        This function returns the value of CRRA utility with σ\n",
    "        u(c) = c**(1-σ)/(1-σ)\n",
    "        '''\n",
    "        if self.σ != 1:\n",
    "            uu = cons**(1-self.σ)/(1-self.σ)\n",
    "        else:\n",
    "            uu = np.log(cons)\n",
    "        return uu\n",
    "\n",
    "    def get_V(self):\n",
    "        '''\n",
    "        This function returns the value function\n",
    "        '''\n",
    "        return self.V\n",
    "\n",
    "    def get_kp(self):\n",
    "        '''\n",
    "        This function returns the policy function\n",
    "        '''\n",
    "        return self.kp\n",
    "    \n",
    "    def set_V(self,VV):\n",
    "        '''\n",
    "        This function updates the value function\n",
    "        '''\n",
    "        self.V   = VV\n",
    "        \n",
    "    def set_kp(self,kp):\n",
    "        '''\n",
    "        This function updates the policy function\n",
    "        '''\n",
    "        self.kp   = kp        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "872733b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman(kp,k0,kgrid,VV,α,β,σ,δ):\n",
    "    '''\n",
    "    This function computes bellman equation for a given state k0.\n",
    "    Input:\n",
    "        kp: an evaluating point of k'\n",
    "        k0: current state of capital-labor ratio\n",
    "        kgrid: predetermined discrete state space\n",
    "        VV: next period's value function at k'\n",
    "        α,β,σ,δ: model parameters\n",
    "    Output:\n",
    "        -vv: value function (negative so that fminbound search for a minimum value)\n",
    "    ''' \n",
    "\n",
    "    # Interpolate next period's value function evaluated at k'\n",
    "    # using 1-dimensional interpolation function in numpy\n",
    "    V1         = np.interp(kp,kgrid,VV)\n",
    "        \n",
    "    # Interpolated value cannot be NaN or Inf\n",
    "    if np.isnan(V1) or np.isinf(V1): print(\"bellman: V1 is NaN.\")\n",
    "\n",
    "    # Compute consumption at a given k0 and k'\n",
    "    cons = k0**α + (1 - δ)*k0 - kp\n",
    "    \n",
    "    # Consumption must be non-negative\n",
    "    if cons<=0:\n",
    "        # Assign some large negative values\n",
    "        vv = cons*1000\n",
    "    else:\n",
    "        # Compute value function\n",
    "        vv  = cons**(1-σ)/(1-σ) + β*V1\n",
    "    \n",
    "    return -vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d57291",
   "metadata": {},
   "source": [
    " (a) Please complete the missing code (...) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cd0792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fminbound\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "# Set values on model parameters\n",
    "α, β, σ, δ, nk = 0.34, 0.95, 2, 0.01, 100\n",
    "\n",
    "# Instantiate NGM object\n",
    "hh = ngm_pfi(nk, α, β, σ, δ)\n",
    "\n",
    "# Create grid points over the state space\n",
    "kgrid = hh.init_kgrid()\n",
    "\n",
    "# Set tolerance parameter and an arbitrary initial difference\n",
    "tol = 1e-5\n",
    "diff = 1e5\n",
    "niter  = 0\n",
    "    \n",
    "#Iterate until the difference of old and new value functions are less than the tolerance level\n",
    "tic = time.perf_counter()\n",
    "while diff>tol and niter<500:\n",
    "\n",
    "    # Start with the current policy function\n",
    "    kp_old     = ...  # policy function from the previous iteration: h(k(t)) = k(t+1)\n",
    "    cons_old   = ...  # compute consumption associated with the policy function\n",
    "    V_old      = ...  # compute value function from the updating rule\n",
    "    kp_new     = np.zeros(nk)   # empty policy function\n",
    "    \n",
    "    # Solve for optimal capital and value function at each point of state k\n",
    "    for ik in range(nk):\n",
    "        k0 = kgrid[ik]\n",
    "        kmin = kgrid[0]\n",
    "        kmax = kgrid[nk-1]\n",
    "        kp_new[ik] = fminbound(bellman,kmin,kmax,args=(k0,kgrid,V_old,α,β,σ,δ))\n",
    "        \n",
    "    # Update the policy functions\n",
    "    hh.set_kp(kp_new)\n",
    "    \n",
    "    # Compute the difference between new and old policy functions by sup norm\n",
    "    diff = np.max(abs(...))\n",
    "    niter += 1\n",
    "    if niter%10==0:\n",
    "        sys.stdout.write('Number of Iteration = %d, Difference = %f\\n' % (niter,diff))\n",
    "\n",
    "toc = time.perf_counter()\n",
    "sys.stdout.write('Value function converged. The elapsed time = %f seconds.\\n' % (toc-tic))\n",
    "\n",
    "# Plot Value Function\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plt.plot(hh.kgrid, hh.V,label=\"$V(k)$\")\n",
    "plt.legend(loc='lower right', fontsize = 14)\n",
    "plt.show()\n",
    "\n",
    "# Plot Policy Function\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plt.plot(hh.kgrid, hh.kp,label=\"$k'=g(k)$\")\n",
    "plt.plot(hh.kgrid, hh.kgrid,label=\"$k=k'$\")\n",
    "plt.legend(loc='lower right', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd98f9b0",
   "metadata": {},
   "source": [
    "(b) Can you find out as to why this algorithm doesn't work to get a convergence on the policy function?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
